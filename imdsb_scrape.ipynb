{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is meant to import screenplays from imsdb.com (Futurama) and automatically import all of them for preprocessing. \n",
    "\n",
    "I've tested the current function and this works with separating names from characters for two scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scrape(link, sname):\n",
    "    page = requests.get(link) #Go to IMSDB link\n",
    "    soup = BeautifulSoup(page.content) #Pull the content\n",
    "    links = soup.find_all('a') #Pull links\n",
    "    titles = [] \n",
    "    for title in links:\n",
    "        temp = title.get('title') #only pull links with the word title in them\n",
    "        if (temp is not None) and ('Script' in temp): #Only Pull values that are not none and with the words script in them\n",
    "            if temp not in titles:\n",
    "                titles.append(temp)\n",
    "    titles=titles[1:-1] #ignore the first and last lines\n",
    "    nlink=[] \n",
    "    for index in range(len(titles)):\n",
    "        titles[index]=titles[index].split('Script')[0]\n",
    "        nlink.append(titles[index])\n",
    "        nlink[index]=nlink[index].replace(\" \",\"-\")\n",
    "        nlink[index]=nlink[index].strip(\"-\")\n",
    "        nlink[index]=\"https://www.imsdb.com/transcripts/\"+sname+'-'+nlink[index]+\".html\"\n",
    "    return np.asarray(nlink), np.asarray(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gscrnplay(link):\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    text = soup.find('td', class_= 'scrtext').get_text()\n",
    "    text = text.split('THE END')[0] #We don't need anything below 'THE END'\n",
    "    temp=text.split('\\n\\n') #Separates the Title Sequence since it's unneeded. \n",
    "    ### Need to fix this so that it's automated. Sectioned 8 might not be used for all TV scripts\n",
    "    scrnplay = ''.join(temp[8:]) #Connect the strings back together, except the title sequence\n",
    "    return scrnplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcharnames(scrnplay):\n",
    "    characters = scrnplay.split(' \\n') #Remove lines that have issues\n",
    "    #names is a list of the characters in the dialogue.\n",
    "    names = []; #Create empty list\n",
    "    for test in characters:\n",
    "        scr = test.split('\\n') #Separate more lines\n",
    "        if len(scr) > 1:\n",
    "            pname=(scr[0].strip()).split('\\n') #Remove spaces and the more lines to separate the character names from dialogue\n",
    "            for n in pname:\n",
    "                if n.isupper() is True: #Characters are separated from dialogue via uppercase.\n",
    "                    n= n.split('[')\n",
    "                    n = n[0]\n",
    "                    n = ''.join(u for u in n if u not in (\".\"))\n",
    "                    n = n.strip()\n",
    "                    n = n.strip('\"')\n",
    "                    if n not in names:\n",
    "                        names.append(n)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data_scrape('https://www.imsdb.com/TV/Futurama.html', 'Futurama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [];\n",
    "for i,j in zip(titles[0], titles[1]):\n",
    "    info = {};\n",
    "    scrnplay = gscrnplay(i)\n",
    "    data.append({\n",
    "        \"title\" : j,\n",
    "        \"scrnplay\" : scrnplay,\n",
    "        \"characters\" : gcharnames(scrnplay) \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars University \n",
      "FARNSWORTH\n",
      "FRY\n",
      "BENDER\n",
      "LEELA\n",
      "FRATBOT #1\n",
      "FRATBOT #2\n",
      "FRATBOT #3\n",
      "OILY\n",
      "FATBOT\n",
      "GEARSHIFT\n",
      "MAN #1\n",
      "MAN #2\n",
      "AMY\n",
      "MEIDERNEYER\n",
      "CHET\n",
      "MONKEY\n",
      "GUENTER\n",
      "TEACHER\n",
      "VERNON\n",
      "WOMAN\n",
      "CHRISSY\n",
      "MR WONG\n",
      "STUDENT\n"
     ]
    }
   ],
   "source": [
    "print(data[10]['title'])\n",
    "for i in data[10]['characters']:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
